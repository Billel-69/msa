const { OpenAI } = require('openai');
require('dotenv').config();
const { generateRagAnswer } = require('../services/ragService');
const { recordAIConversation, getUserConversationHistory } = require('../services/aiConversationService');
const { recordUsage } = require('../services/usageServiceDB');

// Initialiser OpenAI avec la cl√© API
let openai = null;
try {
  if (process.env.OPENAI_API_KEY) {
    openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    });
  } else {
    console.warn("Cl√© API OpenAI non trouv√©e dans les variables d'environnement");
  }
} catch (error) {
  console.warn("Erreur lors de l'initialisation de l'API OpenAI:", error.message);
}

const ASSISTANT_ID = process.env.ASSISTANT_ID;

// Fonction pour g√©rer les messages de chat avec basculement niveau 1/2
exports.processMessage = async (req, res) => {
  const startTime = Date.now();
  
  try {
    const { message, thread_id, history = [] } = req.body;
    const userId = req.userId;
    const sessionId = req.body.session_id || thread_id;
    
    console.log("üì® Message re√ßu:", message);
    console.log("üîç Niveau d√©termin√©:", req.isLevel2 ? "2 (RAG)" : "1 (OpenAI)");
    
    // Si cooldown actif, informer l'utilisateur
    if (req.cooldownInfo && req.cooldownInfo.isOnCooldown) {
      console.log(`‚è∞ Utilisateur en cooldown: ${req.cooldownInfo.remainingHours}h restantes`);
    }
    
    let response, modelUsed, finalThreadId;
    
    // NIVEAU 2 - Utilisation du RAG
    if (req.isLevel2) {
      console.log("ü§ñ Utilisation du RAG (niveau 2)");
      
      try {
        // NOUVEAU : R√©cup√©rer l'historique depuis la BD pour CE thread sp√©cifique
        let conversationHistory = [];
        
        if (userId && thread_id) {
          // Importer mysql pour la requ√™te personnalis√©e
          const mysql = require('mysql2/promise');
          const connection = await mysql.createConnection({
            host: process.env.DB_HOST || 'localhost',
            user: process.env.DB_USER || 'root',
            password: process.env.DB_PASS || '',
            database: process.env.DB_NAME || 'msa'
          });
          
          try {
            // R√©cup√©rer uniquement les conversations de ce thread
            const [conversations] = await connection.execute(`
              SELECT message, response, created_at 
              FROM ai_conversations 
              WHERE user_id = ? 
              AND (session_id = ? OR session_id LIKE ?)
              ORDER BY created_at ASC
              LIMIT 20
            `, [userId, thread_id, `%${thread_id}%`]);
            
            // Transformer en format attendu par le RAG
            conversationHistory = conversations.map(conv => [
              { role: 'user', content: conv.message },
              { role: 'assistant', content: conv.response }
            ]).flat();
            
            console.log(`üìö Historique r√©cup√©r√©: ${conversationHistory.length} messages du thread ${thread_id}`);
            
          } finally {
            await connection.end();
          }
        }
        
        // Appel au service RAG AVEC L'HISTORIQUE
        response = await generateRagAnswer(message, conversationHistory);
        modelUsed = 'rag_local';
        finalThreadId = thread_id || sessionId || `rag_session_${Date.now()}`;
        
        console.log("‚úÖ R√©ponse RAG g√©n√©r√©e avec succ√®s");
        
      } catch (ragError) {
        console.error("‚ùå Erreur RAG:", ragError.message);
        
        // Si le RAG √©choue et qu'on n'est pas en cooldown, fallback sur OpenAI
        if (!req.cooldownInfo?.isOnCooldown) {
          console.log("üîÑ Fallback sur OpenAI suite √† erreur RAG");
          req.isLevel2 = false;
        } else {
          // En cooldown, on doit rester sur RAG
          return res.status(503).json({
            error: "Service temporairement indisponible. Veuillez r√©essayer dans quelques instants.",
            model_used: 'rag_local',
            cooldown_info: req.cooldownInfo
          });
        }
      }
    }
    
    // NIVEAU 1 - Utilisation d'OpenAI
    if (!req.isLevel2) {
      console.log("üåü Utilisation d'OpenAI (niveau 1)");
      
      if (!openai) {
        throw new Error("Service OpenAI non configur√©");
      }
      
      // Cr√©er un nouveau thread si n√©cessaire ou si le thread n'existe pas
      let threadId = thread_id;
      let threadExists = false;
      
      if (threadId) {
        try {
          // V√©rifier si le thread existe c√¥t√© OpenAI
          await openai.beta.threads.retrieve(threadId);
          threadExists = true;
          console.log("Thread existant trouv√©:", threadId);
        } catch (error) {
          console.log("Thread inexistant ou supprim√©:", threadId, "- Cr√©ation d'un nouveau thread");
          threadExists = false;
        }
      }
      
      if (!threadId || !threadExists) {
        console.log("Cr√©ation d'un nouveau thread");
        const thread = await openai.beta.threads.create();
        threadId = thread.id;
        console.log("Nouveau thread cr√©√©:", threadId);
      }
      
      // Ajouter le message au thread
      await openai.beta.threads.messages.create(threadId, {
        role: "user",
        content: message
      });
      
      // Ex√©cuter l'assistant
      console.log("Ex√©cution de l'assistant");
      const run = await openai.beta.threads.runs.create(threadId, {
        assistant_id: ASSISTANT_ID
      });
      
      // Attendre la r√©ponse
      let runStatus;
      do {
        await new Promise(resolve => setTimeout(resolve, 1000));
        runStatus = await openai.beta.threads.runs.retrieve(run.id, {
          thread_id: threadId
        });
      } while (runStatus.status !== "completed" && runStatus.status !== "failed");
      
      if (runStatus.status === "failed") {
        throw new Error("L'assistant n'a pas pu g√©n√©rer de r√©ponse");
      }
      
      // R√©cup√©rer la r√©ponse
      const messages = await openai.beta.threads.messages.list(threadId);
      const assistantMessages = messages.data.filter(msg => msg.role === "assistant");
      const lastMessage = assistantMessages[0];
      
      if (!lastMessage) {
        throw new Error("Pas de r√©ponse de l'assistant");
      }
      
      response = lastMessage.content[0].type === "text" 
        ? lastMessage.content[0].text.value 
        : "D√©sol√©, je n'ai pas pu g√©n√©rer de r√©ponse textuelle.";
      
      modelUsed = 'openai';
      finalThreadId = threadId;
    }
    
    // Calculer le temps de r√©ponse
    const responseTime = Date.now() - startTime;
    
    // Enregistrer la conversation dans la BD
    if (userId) {
      await recordAIConversation({
        user_id: userId,
        session_id: finalThreadId, // Utiliser le thread_id comme session_id pour la coh√©rence
        message: message,
        response: response,
        model_used: modelUsed,
        tokens_used: req.estimatedTokens || 0,
        response_time_ms: responseTime
      });
    }
    
    // NE PAS enregistrer les tokens ici car c'est d√©j√† fait dans le middleware
    // Le middleware enhancedTokenMeter s'en charge d√©j√†
    
    // R√©ponse finale
    const responseData = {
      answer: response,
      thread_id: finalThreadId,
      model_used: modelUsed,
      response_time_ms: responseTime
    };
    
    // Ajouter les infos de cooldown si pertinent
    if (req.cooldownInfo?.isOnCooldown) {
      responseData.cooldown_info = {
        is_active: true,
        hours_remaining: Math.ceil(req.cooldownInfo.hoursRemaining),
        can_switch_back_at: req.cooldownInfo.canSwitchBackAt
      };
    }
    
    console.log(`‚úÖ R√©ponse envoy√©e (${modelUsed}) en ${responseTime}ms`);
    res.json(responseData);
    
  } catch (error) {
    console.error("‚ùå Erreur processMessage:", error.message);
    if (error.response) {
      console.error("D√©tails de l'erreur:", error.response.data);
    }
    
    res.status(500).json({ 
      error: "Une erreur s'est produite lors du traitement de votre message.",
      details: process.env.NODE_ENV === 'development' ? error.message : undefined
    });
  }
};

// G√©n√©ration de questions de quiz √©ducatif (fonction existante inchang√©e)
exports.generateQuizQuestions = async (subject, niveau, count = 5) => {
  try {
    // V√©rifier si OpenAI est initialis√©
    if (!openai) {
      console.warn("OpenAI API non initialis√©e, utilisation des questions par d√©faut");
      return getDefaultQuestions(subject, niveau);
    }
    
    // Ajout de logs d√©taill√©s pour le debug
    console.log(`G√©n√©ration pour sujet="${subject}" (type: ${typeof subject}) et niveau="${niveau}" (type: ${typeof niveau})`);
    // Normalisation du sujet pour √©viter les probl√®mes d'accents et de casse
    const normalizedSubject = subject ? subject.toLowerCase().normalize("NFD").replace(/[\u0300-\u036f]/g, "") : 'mathematiques';
    const normalizedNiveau = niveau || '3e';
    console.log(`Sujet normalis√©: "${normalizedSubject}", Niveau normalis√©: "${normalizedNiveau}"`);
    // Construire le prompt pour OpenAI en insistant sur le sujet et le niveau
    const prompt = `
      Tu es un professeur qui es expert dans toutes les mati√®res de la 3√®me √† la Terminale,tu connais les programmes et les attendus du syst√®me francais pour chaque mati√®res et niveau
      G√©n√®re exactement ${count} questions de quiz √©ducatif en fran√ßais strictement sur le sujet "${normalizedSubject}" pour un niveau scolaire "${normalizedNiveau}".
      IMPORTANT: Les questions DOIVENT √™tre sp√©cifiquement sur ${normalizedSubject} et adapt√©es au niveau ${normalizedNiveau}.
      Si le sujet est "histoire-geo" ou contient "histoire" ou "geo", les questions doivent porter sur l'histoire ou la g√©ographie, PAS sur les math√©matiques ou d'autres mati√®res.
      Aucune question ne doit √™tre triviale ou r√©p√©t√©e.
      Chaque question doit √™tre originale, claire, et p√©dagogique.
      Chaque question doit avoir exactement 4 options de r√©ponses et une seule r√©ponse correcte.
      Ajoute une courte explication pour chaque r√©ponse correcte.
      Format JSON requis:
      {
        "questions": [
          {
            "question": "Texte de la question sur ${normalizedSubject}",
            "options": ["Option A", "Option B", "Option C", "Option D"],
            "correctAnswer": "Option correcte (exactement comme dans les options)",
            "explanation": "Explication courte et p√©dagogique"
          }
        ]
      }
    `;
    const response = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        {
          role: "system",
          content: "Tu es un professeur expert qui g√©n√®re des questions de quiz √©ducatives adapt√©es √† diff√©rents niveaux scolaires et mati√®res."
        },
        {
          role: "user",
          content: prompt
        }
      ],
      temperature: 0.4,
      response_format: { type: "json_object" }
    });
    const content = response.choices[0].message.content;
    console.log("R√©ponse OpenAI re√ßue:", content.substring(0, 100) + "...");
    let jsonResponse;
    try {
      jsonResponse = JSON.parse(content);
    } catch (e) {
      console.error("Erreur de parsing JSON OpenAI:", e);
      return getDefaultQuestions(subject, niveau);
    }
    if (!jsonResponse.questions || !Array.isArray(jsonResponse.questions) || jsonResponse.questions.length === 0) {
      console.error("Format de r√©ponse OpenAI invalide:", content);
      return getDefaultQuestions(subject, niveau);
    }
    const formattedQuestions = jsonResponse.questions.map(q => ({
      question: q.question,
      options: q.options && q.options.length === 4 ? q.options : generateDefaultOptions(q.correctAnswer),
      correctAnswer: q.correctAnswer,
      explanation: q.explanation || `La bonne r√©ponse est: ${q.correctAnswer}`
    })).slice(0, count);
    return formattedQuestions;
  } catch (error) {
    console.error("Erreur lors de la g√©n√©ration des questions avec OpenAI:", error);
    return getDefaultQuestions(subject, niveau);
  }
};

function generateDefaultOptions(correctAnswer) {
  return [
    correctAnswer,
    `Option incorrecte A`,
    `Option incorrecte B`,
    `Option incorrecte C`
  ];
}

function getDefaultQuestions(subject, niveau) {
  const questionSets = {
    'math√©matiques': {
      '6e': [
        { question: 'Combien font 5 √ó 8 ?', options: ['35', '40', '45', '50'], correctAnswer: '40', explanation: '5 √ó 8 = 40' },
        { question: 'Quel est le r√©sultat de 12 + 9 ?', options: ['19', '21', '23', '25'], correctAnswer: '21', explanation: '12 + 9 = 21' }
      ],
      '3e': [
        { question: 'R√©solvez: 2x + 5 = 15', options: ['x = 5', 'x = 10', 'x = 3', 'x = 7'], correctAnswer: 'x = 5', explanation: '2x = 15 - 5 = 10, donc x = 5' },
        { question: 'Quelle est la racine carr√©e de 64 ?', options: ['6', '7', '8', '9'], correctAnswer: '8', explanation: '8¬≤ = 64' }
      ],
      '2nde': [
        { question: 'R√©solvez: x¬≤ - 4 = 0', options: ['x = 2', 'x = ¬±2', 'x = 4', 'x = ¬±4'], correctAnswer: 'x = ¬±2', explanation: 'x¬≤ = 4 donc x = ¬±2' }
      ],
      '1√®re': [
        { question: 'Quelle est la d√©riv√©e de f(x) = x¬≤?', options: ['f\'(x) = 2x', 'f\'(x) = x', 'f\'(x) = x¬≤', 'f\'(x) = 0'], correctAnswer: 'f\'(x) = 2x', explanation: 'La d√©riv√©e de x^n est n*x^(n-1)' }
      ],
      'Terminale': [
        { question: 'Calculez la limite de (1+1/n)^n quand n tend vers l\'infini', options: ['0', '1', 'e', '‚àû'], correctAnswer: 'e', explanation: 'Cette limite est la d√©finition du nombre e ‚âà 2,718' }
      ]
    },
    'fran√ßais': {
      '3e': [
        { question: 'Qui a √©crit "Les Mis√©rables" ?', options: ['Victor Hugo', 'Albert Camus', '√âmile Zola', 'Gustave Flaubert'], correctAnswer: 'Victor Hugo', explanation: '"Les Mis√©rables" est une ≈ìuvre de Victor Hugo publi√©e en 1862' }
      ],
      'Terminale': [
        { question: 'Quelle figure de style est utilis√©e dans "Cette femme est une fleur" ?', options: ['Comparaison', 'M√©taphore', 'Hyperbole', 'Oxymore'], correctAnswer: 'M√©taphore', explanation: 'La m√©taphore √©tablit une identification entre deux √©l√©ments sans utiliser de terme de comparaison' }
      ]
    },
    'anglais': {
      'Terminale': [
        { question: 'What is the past simple of "to begin"?', options: ['begun', 'began', 'beginned', 'beginning'], correctAnswer: 'began', explanation: 'Le pr√©t√©rit du verbe irr√©gulier "to begin" est "began"' }
      ]
    },
    'histoire-g√©o': {
      'Terminale': [
        { question: 'Quand a eu lieu la R√©volution fran√ßaise ?', options: ['1689', '1789', '1889', '1989'], correctAnswer: '1789', explanation: 'La R√©volution fran√ßaise a d√©but√© en 1789 avec la prise de la Bastille le 14 juillet' }
      ]
    },
    'physique-chimie': {
      'Terminale': [
        { question: 'Quelle est l\'unit√© de mesure de la force ?', options: ['Watt', 'Joule', 'Newton', 'Pascal'], correctAnswer: 'Newton', explanation: 'La force se mesure en newtons (N) dans le Syst√®me International' }
      ]
    }
  };
  const normalizedSubject = subject?.toLowerCase().normalize("NFD").replace(/[\u0300-\u036f]/g, "") || 'math√©matiques';
  let bestMatch = 'math√©matiques';
  for (const key in questionSets) {
    if (key.includes(normalizedSubject) || normalizedSubject.includes(key)) {
      bestMatch = key;
      break;
    }
  }
  const subjectQuestions = questionSets[bestMatch] || questionSets['math√©matiques'];
  const levelQuestions = subjectQuestions[niveau] || 
                        subjectQuestions['Terminale'] || 
                        subjectQuestions['3e'] || 
                        Object.values(subjectQuestions)[0];
  return levelQuestions;
}
